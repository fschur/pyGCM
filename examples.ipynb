{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import numpy2ri\n",
    "\n",
    "from pyGCM.gcm_test import GCMTest\n",
    "from pyGCM.residual_methods import linear_regression_residuals\n",
    "\n",
    "# Make sure rpy2's conversion is activated\n",
    "numpy2ri.activate()\n",
    "\n",
    "# Import the R package containing gcm_test\n",
    "GCM = importr('GeneralisedCovarianceMeasure')\n",
    "\n",
    "\n",
    "def compare_gcm(E, X, Y,\n",
    "                get_resid='GP',\n",
    "                categorical_E=False,\n",
    "                categorical_X=False,\n",
    "                categorical_Y=False,\n",
    "                resid_E=None,\n",
    "                resid_Y=None):\n",
    "    \"\"\"\n",
    "    Compare Python-based GCM test with the R-based GCM test (kernel ridge).\n",
    "\n",
    "    If 'resid_E' or 'resid_Y' are provided, we pass them directly\n",
    "    to the Python GCM test, bypassing internal residual computation.\n",
    "\n",
    "    Similarly, if 'resid_E'/'resid_Y' are given, we also pass them\n",
    "    to R's gcm_test() as 'resid.XonZ' or 'resid.YonZ', aligned\n",
    "    with how we map Python variables to R.\n",
    "\n",
    "    Args:\n",
    "        E, X, Y (np.ndarray): Data arrays with shape (n_samples, ...)\n",
    "        get_resid (str): 'GP', 'linear', 'categorical', or callable.\n",
    "        categorical_E, categorical_X, categorical_Y (bool):\n",
    "            Indicate which variables should be treated as categorical in Python GCM.\n",
    "        resid_E, resid_Y (np.ndarray or None):\n",
    "            Optional precomputed residuals for E, Y given X (shape ~ (n,) or (n,1)).\n",
    "\n",
    "    Returns:\n",
    "        (float, float, float): (python_test_stat, python_p_val, r_p_val)\n",
    "    \"\"\"\n",
    "    py_gcm_tester = GCMTest(get_resid=get_resid)\n",
    "    python_test_stat, python_p_val = py_gcm_tester.fit(\n",
    "        E, X, Y,\n",
    "        resid_E=resid_E,\n",
    "        resid_Y=resid_Y,\n",
    "        categorical_E=categorical_E,\n",
    "        categorical_X=categorical_X,\n",
    "        categorical_Y=categorical_Y\n",
    "    )\n",
    "\n",
    "\n",
    "    r_resid_XonZ = None\n",
    "    r_resid_YonZ = None\n",
    "    if resid_Y is not None and resid_E is not None:\n",
    "        r_resid_XonZ = resid_Y.reshape(-1, 1)  # Python's Y|X\n",
    "        r_resid_YonZ = resid_E.reshape(-1, 1)  # Python's E|X\n",
    "\n",
    "        r_gcm_result = GCM.gcm_test(\n",
    "            X=Y,\n",
    "            Y=E,\n",
    "            Z=X,\n",
    "            regr_method=\"kernel.ridge\",\n",
    "            resid_XonZ=r_resid_XonZ,\n",
    "            resid_YonZ=r_resid_YonZ\n",
    "        )\n",
    "    else:\n",
    "        # No precomputed residuals => let R do the regression\n",
    "        r_gcm_result = GCM.gcm_test(\n",
    "            X=Y,\n",
    "            Y=E,\n",
    "            Z=X,\n",
    "            regr_method=\"kernel.ridge\"\n",
    "        )\n",
    "\n",
    "    r_p_val = r_gcm_result.rx2('p.value')[0]\n",
    "\n",
    "    print(\"Python GCM Test (possibly with precomputed residuals):\")\n",
    "    print(f\"   Test Statistic = {python_test_stat:.6f}\")\n",
    "    print(f\"   p-value        = {python_p_val:.6g}\")\n",
    "\n",
    "    print(\"R GCM Test (kernel.ridge):\")\n",
    "    print(f\"   p-value        = {r_p_val:.6g}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    return python_test_stat, python_p_val, r_p_val\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(42)\n",
    "    n = 100\n",
    "\n",
    "    ############################################################################\n",
    "    # TEST 1) All Continuous\n",
    "    ############################################################################\n",
    "    X_continuous = np.random.randn(n, 2)\n",
    "    E_continuous = 0.5 * X_continuous[:, [0]] + 0.1 * np.random.randn(n, 1)\n",
    "    Y_continuous = 0.8 * X_continuous[:, [1]] + 0.1 * np.random.randn(n, 1)\n",
    "\n",
    "    print(\"=== TEST 1: All Continuous ===\")\n",
    "    compare_gcm(E_continuous, X_continuous, Y_continuous,\n",
    "                get_resid='GP',\n",
    "                categorical_E=False,\n",
    "                categorical_X=False,\n",
    "                categorical_Y=False)\n",
    "\n",
    "    ############################################################################\n",
    "    # TEST 2) E is Categorical\n",
    "    ############################################################################\n",
    "    X_continuous = np.random.randn(n, 2)\n",
    "    E_categorical = np.random.choice([0, 1, 2], size=(n, 1), p=[0.3, 0.5, 0.2])\n",
    "    Y_continuous = 0.8 * X_continuous[:, [1]] + 0.1 * np.random.randn(n, 1)\n",
    "\n",
    "    print(\"=== TEST 2: E is Categorical ===\")\n",
    "    compare_gcm(E_categorical, X_continuous, Y_continuous,\n",
    "                get_resid='GP',\n",
    "                categorical_E=True,\n",
    "                categorical_X=False,\n",
    "                categorical_Y=False)\n",
    "\n",
    "    ############################################################################\n",
    "    # TEST 3) X is Categorical\n",
    "    ############################################################################\n",
    "    E_continuous = 0.5 * np.random.randn(n, 1)  # some continuous E\n",
    "    X_categorical = np.random.choice([0, 1, 2], size=(n, 1))\n",
    "    Y_continuous = 0.5 * X_categorical + 0.1 * np.random.randn(n, 1)\n",
    "\n",
    "    print(\"=== TEST 3: X is Categorical ===\")\n",
    "    compare_gcm(E_continuous, X_categorical, Y_continuous,\n",
    "                get_resid='categorical',\n",
    "                categorical_E=False,\n",
    "                categorical_X=True,\n",
    "                categorical_Y=False)\n",
    "\n",
    "    ############################################################################\n",
    "    # TEST 4) Precomputed Residuals (Both Python & R)\n",
    "    ############################################################################\n",
    "    # We'll re-use continuous data for clarity. Suppose we want to do a linear\n",
    "    # regression for Y on X, E on X, store the residuals, and hand them to\n",
    "    # both Python and R tests so neither fits any regression internally.\n",
    "\n",
    "    X_cont = np.random.randn(n, 2)\n",
    "    E_cont = 0.5 * X_cont[:, [0]] + 0.1 * np.random.randn(n, 1)\n",
    "    Y_cont = 0.8 * X_cont[:, [1]] + 0.1 * np.random.randn(n, 1)\n",
    "\n",
    "    # Precompute residuals externally\n",
    "    resid_E_lin = linear_regression_residuals(E_cont, X_cont)  # shape ~ (n,) or (n,1)\n",
    "    resid_Y_lin = linear_regression_residuals(Y_cont, X_cont)\n",
    "\n",
    "    print(\"=== TEST 4: Precomputed Residuals ===\")\n",
    "    compare_gcm(\n",
    "        E_cont, X_cont, Y_cont,\n",
    "        get_resid='linear',  # It's ignored for E,Y since we're passing precomputed anyway\n",
    "        categorical_E=False,\n",
    "        categorical_X=False,\n",
    "        categorical_Y=False,\n",
    "        resid_E=resid_E_lin,\n",
    "        resid_Y=resid_Y_lin\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
